import re
import webbrowser
import googleapiclient.discovery
import tensorflow as tf
from transformers import CLIPTokenizer, TFCLIPModel
import numpy as np

# ä½¿ç”¨clipï¼Œåå‘èªæ„æœå°‹ï¼Œä½†æ˜¯æœç´¢çµæœæ˜¯çœŸçš„å¾ˆå·®
# é€™å¾ˆåå‘æ–¼æ˜¯é è‘—æè¿°ä¸€æ®µæ­Œæ›²ä»‹ç´¹ä¾†å»å°‹æ‰¾æˆ‘æƒ³è¦çš„æ­Œæ›²ï¼Œä½†æ˜¯é€™çµ•å°æœƒéœ€è¦å°æ–¼æ¯å€‹æƒ³è¦æ‰¾çš„æ­Œæ›²é€²è¡Œæ›´æ·±å…¥çš„æ¶ˆæ¯æ¢ç´¢ä¸¦é€²è¡Œå¾®èª¿æ‰èƒ½åšåˆ°
clip_model = TFCLIPModel.from_pretrained("openai/clip-vit-base-patch32")
clip_tokenizer = CLIPTokenizer.from_pretrained("openai/clip-vit-base-patch32")

# è¨­å®š YouTube API
YOUTUBE_API_KEY = "" #é€™æˆ‘ä¸èƒ½çµ¦å§? ç”¨è‡ªå·±çš„å»
YOUTUBE_PLAYLIST_ID = "PLXuNaCgnseuvZPDI1DfyMXSSsbtF4KHL7"
YOUTUBE_BASE_URL = "https://www.youtube.com/watch?v="

def clean_title(title): #è™•ç†æ­Œæ›²æ¨™é¡Œ
    
    title = re.sub(r"\(.*?\)|\[.*?\]|\{.*?\}", "", title)  # ç§»é™¤æ‹¬è™Ÿå…§å…§å®¹
    title = re.sub(r"[^a-zA-Z0-9\u4e00-\u9fa5 ]", "", title)  # ç§»é™¤ç‰¹æ®Šå­—ç¬¦
    return title.strip().lower()

def get_playlist_videos(api_key, playlist_id):
    #å–å¾— YouTube æ­Œå–®ä¸­çš„æ‰€æœ‰æ­Œæ›²è³‡è¨Š
    youtube = googleapiclient.discovery.build("youtube", "v3", developerKey=api_key)
    
    songs = []
    next_page_token = None

    while True:
        request = youtube.playlistItems().list(
            part="snippet", #æœå°‹æ¨™é¡Œ
            playlistId=playlist_id,
            maxResults=50,
            pageToken=next_page_token
        )
        response = request.execute()
        
        for item in response["items"]:
            video_title = item["snippet"]["title"]
            video_id = item["snippet"]["resourceId"]["videoId"]
            video_link = f"{YOUTUBE_BASE_URL}{video_id}"
            cleaned_title = clean_title(video_title)  #æ¨™é¡Œè™•ç† æœ€çµ‚ç•™ä¸‹æƒ³è¦çš„æ­Œæ›²åç¨±ä»¥åŠæ­Œæ‰‹ æŠŠç‰¹æ®Šç¬¦è™Ÿå»é™¤
            songs.append({"title": cleaned_title, "link": video_link, "raw_title": video_title})
        
        next_page_token = response.get("nextPageToken")
        if not next_page_token:
            break
    
    return songs

def encode_text_clip(text):
    #CLIPå°‡æ–‡æœ¬è½‰ç‚ºå‘é‡
    inputs = clip_tokenizer([text], return_tensors="tf", padding=True, truncation=True)
    text_features = clip_model.get_text_features(**inputs)
    return tf.nn.l2_normalize(text_features, axis=-1)  # L2 æ­£è¦åŒ–

def find_best_matches(user_query, song_list, top_n=5):
    # è½‰æ›ä½¿ç”¨è€…è¼¸å…¥ç‚ºå‘é‡
    user_embedding = encode_text_clip(user_query)
    # è½‰æ›æ‰€æœ‰æ­Œæ›²æ¨™é¡Œç‚ºå‘é‡
    song_titles = [song["title"] for song in song_list]
    song_embeddings = tf.concat([encode_text_clip(title) for title in song_titles], axis=0)
    # ä½¿ç”¨ tf.tensordot è¨ˆç®— cosine similarity
    similarities = tf.tensordot(user_embedding, song_embeddings, axes=[[1], [1]])
    # è½‰æ›ç‚ºNumPyé™£åˆ—ï¼Œç¢ºä¿æ˜¯å‘é‡
    similarities = similarities.numpy().flatten()
    # å–å‡ºTop-Nç›¸ä¼¼åº¦æœ€é«˜çš„ç´¢å¼•
    top_indices = np.argsort(-similarities)[:top_n]  #ä½¿ç”¨è² è™Ÿæ’åºï¼ˆå¾é«˜åˆ°ä½ï¼‰

    return [song_list[idx] for idx in top_indices]

def play_song(url):
    """ç”¨é è¨­ç€è¦½å™¨æ’­æ”¾æ­Œæ›²çš„URL"""
    webbrowser.open(url)

if __name__ == "__main__":
    print("æ­Œå–®æ­Œæ›² å°‹æ‰¾ä¸­")
    songs = get_playlist_videos(YOUTUBE_API_KEY, YOUTUBE_PLAYLIST_ID)
    
    while True:
        user_input = input("\nè«‹è¼¸å…¥ä½ æƒ³è½çš„æ­Œæ›²æè¿°ï¼ˆæˆ–è¼¸å…¥ 'exit' é›¢é–‹ï¼‰ï¼š")
        if user_input.lower() == "exit":
            break
        
        best_songs = find_best_matches(user_input, songs, top_n=5)  #å‰äº”å€‹æ¨è–¦çš„æ­Œæ›²
        print("\nğŸ” æœ€ç¬¦åˆçš„æ­Œæ›²ï¼š")
        for i, song in enumerate(best_songs):
            print(f"{i+1}. {song['raw_title']} - {song['link']}")
        
        #é¸æ“‡è¦æ’­æ”¾å“ªé¦–
        choice = input("æƒ³è½çš„æ­Œæ›²ï¼ˆè¼¸å…¥ 1-5ï¼‰ï¼Œä¹Ÿå¯ä»¥æŒ‰å…¶ä»–çš„è·³éï¼š")
        if choice.isdigit() and 1 <= int(choice) <= 5:
            play_song(best_songs[int(choice) - 1]["link"])
